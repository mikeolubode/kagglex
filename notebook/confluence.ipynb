{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from langchain.document_loaders import ConfluenceLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.document_transformers import (\n",
    "#     LongContextReorder,\n",
    "# )\n",
    "# from langchain.chains import StuffDocumentsChain, LLMChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.llms import OpenAI\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Confluence URL, email, and API token\n",
    "confluence_url = \"https://mikesofts.atlassian.net/\"\n",
    "email = os.environ['EMAIL']\n",
    "api_token = os.environ['API_TOKEN']\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_TOKEN']\n",
    "# Define your Confluence API URL\n",
    "base_url = \"https://mikesofts.atlassian.net/wiki/rest/api\"\n",
    "\n",
    "# Create a session for authentication\n",
    "session = requests.Session()\n",
    "session.auth = (email, api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Machine learning is the study of programs that', metadata={'id': '1048724', 'source': 'https://mikesofts.atlassian.net/wiki/spaces/~614914d4071141006ab46038/pages/1048724/Goals', 'start_index': 5627, 'title': 'Goals'}),\n",
       " Document(page_content='in machine learning is the study of how to', metadata={'id': '918001', 'source': 'https://mikesofts.atlassian.net/wiki/spaces/~614914d4071141006ab46038/pages/918001/Ethics', 'start_index': 305, 'title': 'Ethics'}),\n",
       " Document(page_content='[e] There are several kinds of machine learning.', metadata={'id': '1048724', 'source': 'https://mikesofts.atlassian.net/wiki/spaces/~614914d4071141006ab46038/pages/1048724/Goals', 'start_index': 5785, 'title': 'Goals'}),\n",
       " Document(page_content='can occur if machine learning is used', metadata={'id': '918001', 'source': 'https://mikesofts.atlassian.net/wiki/spaces/~614914d4071141006ab46038/pages/918001/Ethics', 'start_index': 1098, 'title': 'Ethics'}),\n",
       " Document(page_content='a machine learning algorithm that could classify', metadata={'id': '918001', 'source': 'https://mikesofts.atlassian.net/wiki/spaces/~614914d4071141006ab46038/pages/918001/Ethics', 'start_index': 4075, 'title': 'Ethics'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "## get documents from confluence\n",
    "loader = ConfluenceLoader(\n",
    "    url=f\"{confluence_url}wiki\", username=email, api_key=api_token, \n",
    ")\n",
    "\n",
    "documents = loader.load(space_key=\"~614914d4071141006ab46038\", limit=30)\n",
    "\n",
    "## split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 50,\n",
    "    chunk_overlap  = 10,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embeddings.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a retriever\n",
    "cdb = Chroma.from_documents(texts, embedding=embeddings, persist_directory=\"./chroma_db\")\n",
    "retriever = cdb.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "query = \"What is machine learning?\"\n",
    "\n",
    "# Get relevant documents ordered by relevance score\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://mikesofts.atlassian.net/wiki/spaces/~614914d4071141006ab46038/pages/917667/Etymology'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of data science, and it is considered by some to\n",
      "Data science is an interdisciplinary academic\n",
      "Data science is an interdisciplinary field [10]\n",
      "[23] The term \"data science\" has been traced back\n",
      ", data science often involves tasks such as data\n"
     ]
    }
   ],
   "source": [
    "results = \"\\n\".join([doc.page_content for doc in docs])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages: 26\n",
      "Title: mamba setup, ID: 33113\n",
      "Title: Knowledge base, ID: 65638\n",
      "Title: Template - How-to guide, ID: 65650\n",
      "Title: Template - Troubleshooting article, ID: 65664\n",
      "Title: Getting started in Confluence, ID: 98394\n",
      "Title: Overview, ID: 98395\n",
      "Title: Overview, ID: 98634\n",
      "Title: Software Development, ID: 262245\n",
      "Title: Template - Product requirements, ID: 262284\n",
      "Title: Template - Meeting notes, ID: 262298\n",
      "Title: Template - Decision documentation, ID: 262312\n",
      "Title: Get the most out of your software project space, ID: 262326\n",
      "Title: baby mamba, ID: 262359\n",
      "Title: Data Science, ID: 884737\n",
      "Title: Artificial intelligence, ID: 884784\n",
      "Title: In fiction, ID: 885246\n",
      "Title: Etymology, ID: 917667\n",
      "Title: Ethics, ID: 918001\n",
      "Title: Philosophy, ID: 918153\n",
      "Title: Future, ID: 918165\n",
      "Title: Foundations, ID: 983041\n",
      "Title: Data Science and Data Analysis, ID: 983053\n",
      "Title: Goals, ID: 1048724\n",
      "Title: Tools, ID: 1048904\n",
      "Title: Applications, ID: 1048916\n",
      "Title: History, ID: 1049028\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all pages\n",
    "def get_all_pages():\n",
    "    pages = []\n",
    "    start = 0\n",
    "    limit = 50  # You can adjust the limit based on your needs\n",
    "    while True:\n",
    "        url = f\"{base_url}/content\"\n",
    "        params = {\n",
    "            \"start\": start,\n",
    "            \"limit\": limit,\n",
    "            \"expand\": \"version,body.view\",\n",
    "        }\n",
    "        response = session.get(url, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        pages.extend(data.get(\"results\", []))\n",
    "\n",
    "        if data.get(\"size\", 0) < limit:\n",
    "            break\n",
    "\n",
    "        start += limit\n",
    "\n",
    "    return pages\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    all_pages = get_all_pages()\n",
    "    print(f\"Total pages: {len(all_pages)}\")\n",
    "\n",
    "    for page in all_pages:\n",
    "        print(f\"Title: {page['title']}, ID: {page['id']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kagglex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
